
data_path=src/datasets_1d/small
unseen_path=src/datasets_1d/unseen

model predictions:
Prediction Threshold: 0.65
Accuracy: 0.8145732917493621
Classification Report:
              precision    recall  f1-score   support

           0       0.92      0.87      0.89      3150
           1       0.24      0.34      0.28       377

    accuracy                           0.81      3527
   macro avg       0.58      0.61      0.59      3527
weighted avg       0.84      0.81      0.83      3527


Prediction Threshold: 0.7
Accuracy: 0.84264247235611
Classification Report:
              precision    recall  f1-score   support

           0       0.91      0.92      0.91      3150
           1       0.24      0.21      0.22       377

    accuracy                           0.84      3527
   macro avg       0.57      0.57      0.57      3527
weighted avg       0.84      0.84      0.84      3527


Prediction Threshold: 0.75
Accuracy: 0.8729798695775447
Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.96      0.93      3150
           1       0.28      0.12      0.16       377

    accuracy                           0.87      3527
   macro avg       0.59      0.54      0.55      3527
weighted avg       0.83      0.87      0.85      3527


Prediction Threshold: 0.8
Accuracy: 0.889991494187695
Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.99      0.94      3150
           1       0.39      0.05      0.09       377

    accuracy                           0.89      3527
   macro avg       0.64      0.52      0.52      3527
weighted avg       0.84      0.89      0.85      3527



training data config:
SequencesLabelsConfig(
  sequence_length=2,
  future_candles_count=2,
  atr_multiple=1.0,
  atr_length=7,
  pct_increase=10,
  prediction_type=PredictionType.pct_increase,
)

label percentages:
{0: 89.3047521832823, 1: 10.695247816717703}

features config:
FeaturesConfig(
  sma_lengths=[],
  ema_lengths=[],
  rsi_lengths=[],
  stoch_k_lengths=[],
  stoch_d_lengths=[],
  stoch_k_smooth=[],
  mfi_lengths=[],
  adx_lengths=[],
  atr_lengths=[],
  std_lengths=[]
  bb_lengths=[]
  ichimoku=[]
  bb_stds=[]
)

model config:
def create_model(input_shape: tuple[int, int]) -> models.Sequential:
    # add normalization layers
    model = models.Sequential()
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Dense(units=1, activation='sigmoid'))
    optimizer = optimizers.Adam(learning_rate=0.001, clipvalue=1.0)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

