
data_path=src/datasets_12h/largeX2
unseen_path=src/datasets_12h/unseen

model predictions:
Prediction Threshold: 0.65
Accuracy: 0.7530783230312669
Classification Report:
              precision    recall  f1-score   support

           0       0.75      0.96      0.84    163311
           1       0.80      0.34      0.47     80653

    accuracy                           0.75    243964
   macro avg       0.77      0.65      0.66    243964
weighted avg       0.76      0.75      0.72    243964


Prediction Threshold: 0.7
Accuracy: 0.7499426144841043
Classification Report:
              precision    recall  f1-score   support

           0       0.74      0.97      0.84    163311
           1       0.83      0.31      0.45     80653

    accuracy                           0.75    243964
   macro avg       0.78      0.64      0.64    243964
weighted avg       0.77      0.75      0.71    243964


Prediction Threshold: 0.75
Accuracy: 0.7459912118181371
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.98      0.84    163311
           1       0.85      0.28      0.42     80653

    accuracy                           0.75    243964
   macro avg       0.79      0.63      0.63    243964
weighted avg       0.77      0.75      0.70    243964


Prediction Threshold: 0.8
Accuracy: 0.7415807250250037
Classification Report:
              precision    recall  f1-score   support

           0       0.73      0.98      0.84    163311
           1       0.87      0.26      0.40     80653

    accuracy                           0.74    243964
   macro avg       0.80      0.62      0.62    243964
weighted avg       0.78      0.74      0.69    243964



training data config:
SequencesLabelsConfig(
  sequence_length=30,
  future_candles_count=1,
  atr_multiple=1.0,
  atr_length=7,
  pct_increase=1,
  prediction_type=PredictionType.pct_increase,
)

label percentages:
{0: 66.9407788217413, 1: 33.05922117825871}

features config:
FeaturesConfig(
  sma_lengths=[],
  ema_lengths=[],
  rsi_lengths=[],
  stoch_k_lengths=[],
  stoch_d_lengths=[],
  stoch_k_smooth=[],
  mfi_lengths=[],
  adx_lengths=[],
  atr_lengths=[],
  std_lengths=[]
  bb_lengths=[]
  ichimoku=[]
  bb_stds=[]
)

model config:
def create_model(input_shape: tuple[int, int]) -> models.Sequential:
    # add normalization layers
    model = models.Sequential()
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Dense(units=1, activation='sigmoid'))
    optimizer = optimizers.Adam(learning_rate=0.001, clipvalue=1.0)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

