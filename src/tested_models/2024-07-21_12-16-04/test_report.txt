
data_path=src/datasets_1d/small
unseen_path=src/datasets_1d/unseen

model predictions:
Prediction Threshold: 0.65
Accuracy: 0.8936773461865608
Classification Report:
              precision    recall  f1-score   support

           0       0.89      1.00      0.94      3150
           1       0.75      0.01      0.02       377

    accuracy                           0.89      3527
   macro avg       0.82      0.50      0.48      3527
weighted avg       0.88      0.89      0.84      3527


Prediction Threshold: 0.7
Accuracy: 0.8936773461865608
Classification Report:
              precision    recall  f1-score   support

           0       0.89      1.00      0.94      3150
           1       1.00      0.01      0.01       377

    accuracy                           0.89      3527
   macro avg       0.95      0.50      0.48      3527
weighted avg       0.90      0.89      0.84      3527


Prediction Threshold: 0.75
Accuracy: 0.8936773461865608
Classification Report:
              precision    recall  f1-score   support

           0       0.89      1.00      0.94      3150
           1       1.00      0.01      0.01       377

    accuracy                           0.89      3527
   macro avg       0.95      0.50      0.48      3527
weighted avg       0.90      0.89      0.84      3527


Prediction Threshold: 0.8
Accuracy: 0.8931102920328892
Classification Report:
              precision    recall  f1-score   support

           0       0.89      1.00      0.94      3150
           1       0.00      0.00      0.00       377

    accuracy                           0.89      3527
   macro avg       0.45      0.50      0.47      3527
weighted avg       0.80      0.89      0.84      3527



training data config:
SequencesLabelsConfig(
  sequence_length=2,
  future_candles_count=2,
  atr_multiple=1.0,
  atr_length=7,
  pct_increase=10,
  prediction_type=PredictionType.pct_increase,
)

label percentages:
{0: 89.3047521832823, 1: 10.695247816717703}

features config:
FeaturesConfig(
  sma_lengths=[],
  ema_lengths=[],
  rsi_lengths=[],
  stoch_k_lengths=[],
  stoch_d_lengths=[],
  stoch_k_smooth=[],
  mfi_lengths=[],
  adx_lengths=[],
  atr_lengths=[],
  std_lengths=[]
  bb_lengths=[]
  ichimoku=[]
  bb_stds=[]
)

model config:
def create_model(input_shape: tuple[int, int]) -> models.Sequential:
    # add normalization layers
    model = models.Sequential()
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True), input_shape=input_shape))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100, return_sequences=True)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Bidirectional(layers.LSTM(units=100)))
    model.add(layers.Dropout(0.2))
    model.add(layers.Dense(units=1, activation='sigmoid'))
    optimizer = optimizers.Adam(learning_rate=0.001, clipvalue=1.0)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

