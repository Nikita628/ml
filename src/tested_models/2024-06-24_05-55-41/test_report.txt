
data_path=src/datasets_1d/largeX2
unseen_path=src/datasets_1d/unseen

accuracy = 0.7794148823404706

training data config:
SequencesLabelsConfig(
  sequence_length=20,
  future_candles_count=2,
  atr_multiple=1.0,
  atr_length=7,
  pct_increase=5,
  prediction_type=PredictionType.pct_increase,
)

label percentages:
{0: 76.49031447365124, 1: 23.509685526348754}

classification report:
              precision    recall  f1-score   support

           0       0.78      0.99      0.87     79296
           1       0.82      0.08      0.15     24478

    accuracy                           0.78    103774
   macro avg       0.80      0.54      0.51    103774
weighted avg       0.79      0.78      0.70    103774


features config:
FeaturesConfig(
  sma_lengths=[2, 3, 5, 7, 10],
  ema_lengths=[2, 3, 5, 7, 10],
  rsi_lengths=[2, 3, 5, 7, 10],
  stoch_k_lengths=[2, 3, 5, 7, 10],
  stoch_d_lengths=[2, 3, 5, 7, 10],
  stoch_k_smooth=[2, 3, 5, 7, 10],
  mfi_lengths=[2, 3, 5, 7, 10],
  adx_lengths=[2, 3, 5, 7, 10],
  atr_lengths=[2, 3, 5, 7, 10],
  std_lengths=[2, 3, 5, 7, 10]
  bb_lengths=[2, 3, 5, 7, 10]
  ichimoku=[(9, 26, 52), (5, 15, 30), (6, 13, 26), (3, 6, 12)]
  bb_stds=[1.0, 1.5, 2.0]
)

model config:
def create_model(input_shape: tuple[int, int]):
    model = Sequential()
    model.add(Bidirectional(LSTM(units=200, return_sequences=True), input_shape=input_shape))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(units=300, return_sequences=True)))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(units=300, return_sequences=True)))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(units=300, return_sequences=True)))
    model.add(Dropout(0.2))
    model.add(Bidirectional(LSTM(units=200)))
    model.add(Dropout(0.2))
    model.add(Dense(units=1, activation='sigmoid'))
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])
    return model

